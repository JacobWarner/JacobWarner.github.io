<!DOCTYPE HTML>
<!--
	Editorial by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>Scenarios</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<!--[if lte IE 8]><script src="assets/js/ie/html5shiv.js"></script><![endif]-->
		<link rel="stylesheet" href="assets/css/main.css" />
		<!--[if lte IE 9]><link rel="stylesheet" href="assets/css/ie9.css" /><![endif]-->
		<!--[if lte IE 8]><link rel="stylesheet" href="assets/css/ie8.css" /><![endif]-->
	</head>
	<body>

		<!-- Wrapper -->
		<div id="wrapper">

			<!-- Main -->
			<div id="main">
				<div class="inner">

					<!-- Header -->
						<header id="header">
							<a href="index.html" class="logo"><strong>Back to Main Page</strong></a>
						</header>

					<!-- Content -->
						<section>
							<header class="main">
								<h1>Ethical Scenarios</h1>
							</header>


							<hr class="major" />

							<h2>The Deer</h2>
							<span class="image right">
								<img src="images/DeerCar.jpg" alt="" />
							</span>
							<p>Though difficult to quantify due to inconsistent and under-reporting, experts estimate that more than a million car accidents per year in the US are caused by deer. If a deer, or other object, randomly jumped in front of an autonomous car, what would that car decide to do and how? Would the car need to brake hard, or would moderate braking be sufficient? The decision to brake depends on road conditions and whether a tailgater (such as a big truck) is behind you, including its speed to determine the severity of a possible read-end collision.</p>

							<p>What is the object? Is it an animal, a person, or something else? If it’s an animal, are some animals permissible to run over? Squirrels, maybe, but not larger animals, such as deer and cows. How do we determine if its permissible? What if that small animal was your pet dog or cat? If it could swerve and miss the animal, which way does it swerve – left or right? In the US and other nations in which drivers must stay on the right side of the road, some would say to drive off the road to the right, potentially into a ditch or a tree. However, this would likely harm the car and its passengers. The decision may also depend on the number of passengers. The decision to drive into an embankment seems different when only one adult driver is in the car than when several children are inside, too. On the other hand, turning to the left may mean driving into an opposite lane, potentially into a head-on collision. If unavoidable, which vehicle do we choose to crash into? How many people are involved?</p>
							
							<p>In a real-world accident today, a human driver usually has neither the time nor the information needed to make the most ethical or least harmful decisions. They might oversteer into a ditch and to their own death drive or drive into oncoming traffic and kill a family. In both results, no forethought, malice, negligence, or bad intent was shown. However, autonomous cars do not operate under the sanctuary of reasonable instincts; they make potentially life-and-death decisions under no truly urgent time-constraint and therefore incur the responsibility of making better decisions than human drivers reacting reflexively in surprise situations. How do we program them to make such decisions? <sup class="tooltip">5<a class="tooltiptext" href="https://link.springer.com/content/pdf/10.1007%2F978-3-662-48847-8_4.pdf">link.springer.com/content/pdf/10.1007%2F978-3-662-48847-8_4.pdf</a></sup></p>

							<hr class="major" />

							<h2>Self-Sacrifice</h2>
							<p>To help solve ethical dilemmas, one of the first principles we might look for is consequentialism: that the right thing to do is whatever leads to the best results, especially in quantified terms. In our case, we should strive to minimize harm and maximize whatever it is that matters, such as, the number of happy lives.</p>
							
							<p>In this thought-experiment, your future autonomous car is driving you on a narrow road, alongside a cliff. Suddenly, a school bus with 28 children appear around the corner, partially in your lane. Your car calculates that crash is imminent; given the velocities and distance, there is no possible action that can avoid harming you. What should your autonomous car do?</p>
							<span class="image right">
								<img src="images/SelfSacrifice.jpg" alt="" />
							</span>
							<p>A consequentialist would want to optimize results, that is, maximize the number of happy lives and minimize harm. Assuming that all lives in this scenario are more or less equally happy—for instance, there’s no super-happy or super-depressed person, and no very important person who has unusual influence over the welfare of others—they would each count for about the same in our moral calculation. As you like, we may either ignore or account for the issue of whether there is extra value in the life of innocent child who has more years of happiness ahead of her than an average adult; that doesn’t matter much for this scenario.</p>
							
							<p>The autonomous car’s two main choices seem to be: (1) to slam on the brakes and crash into the bus, risking everyone’s lives, or (2) to drive off the cliff, sparing the lives of everyone on the bus. If the odds of death to each person in the accident averaged more than one in 30, then colliding into the bus would yield the expected result of more than one death, up to all 30 persons. If driving off a cliff meant certain death, or the odds of one in one, then the expected result of that would be exactly one death (your own) and no more. Thus, the decision for the autonomous car—if all we care about is maximizing lives and minimizing deaths—is apparently to drive off the cliff and sacrifice the driver, since it is better that only one person should die rather than more than one.</p>
							
							<p>Again, this situation would be entirely different if the car coming around the corner wasn’t a bus but another car with, let’s say, three passengers. If death would be minimized by striking the car instead of veering off the cliff, then that’d be the correct consequentialist choice. But, is consequentialism the correct ethical lens we look through for the future of autonomous cars? <sup class="tooltip">5<a class="tooltiptext" href="https://link.springer.com/content/pdf/10.1007%2F978-3-662-48847-8_4.pdf">link.springer.com/content/pdf/10.1007%2F978-3-662-48847-8_4.pdf</a></sup></p>
							
							<hr class="major" />

							<h2>Ducking Harm</h2>
							<p>Your autonomous car is stopped at an intersection and waits patiently as children cross in front of you. Your car detects a pickup truck quickly approaching from behind, about to cause a rear-end collision with you. The hit wouldn’t cause your death, but it’d surely injure you and damage the car. To avoid this harm, your car is programmed to dash out of the way if it can do so safely. In this case, your car can easily turn right at the intersection and avoid the rear-end collision. But, by doing so, it’d clear a path for the truck to continue through the intersection, seriously injuring some children and killing others.</p>
							
							<p>Would this be the correct way to program an autonomous car? In most cases of an impending rear-end collision, probably yes. But, in this case, the design decision meant saving you from minor injury at the expense of serious injury and death of several children, and this hardly seems to be the right choice. Some may even say you (or the car) are responsible for their deaths: you (or the car) killed the children by removing an obstruction that would’ve prevented harm from falling upon them. Who would be liable? How do we program cars to have morals? <sup class="tooltip">5<a class="tooltiptext" href="https://link.springer.com/content/pdf/10.1007%2F978-3-662-48847-8_4.pdf">link.springer.com/content/pdf/10.1007%2F978-3-662-48847-8_4.pdf</a></sup></p>

						</section>

				</div>
			</div>

			<!-- Sidebar -->
			<div id="sidebar">
				<div class="inner">

					<!-- Menu -->
					<nav id="menu">
						<header class="major">
							<h2>Menu</h2>
						</header>
						<ul>
							<li><a href="index.html">Abstract</a></li>
							<li><a href="history.html">History</a></li>
							<li>
								<span class="opener">Ethical Issues</span>
								<ul>
									<li><a href="trolley_problem.html">Trolley Problem</a></li>
									<li><a href="data_collection.html">Data Collection</a></li>
									<li><a href="abuse.html">Abuse</a></li>
									
								</ul>
							</li>
							<li><a href="scenarios.html">Ethical Scenarios</a></li>
							<li>
								<span class="opener">Legal Issues</span>
								<ul>
									<li><a href="regulation.html">Regulation</a></li>
									<li><a href="liability.html">Liability / Policies</a></li>
								</ul>
							</li>
							<li><a href="statistics.html">Statistics</a></li>
							<li><a href="bibliography.html">Bibliography</a></li>
						</ul>
					</nav>

					<!-- Footer -->
					<footer id="footer">
						<p class="copyright">&copy; Untitled. All rights reserved. Demo Images: <a href="https://unsplash.com">Unsplash</a>. Design: <a href="https://html5up.net">HTML5 UP</a>.</p>
					</footer>
				</div>
			</div>
		</div>

		<!-- Scripts -->
		<script src="assets/js/jquery.min.js"></script>
		<script src="assets/js/skel.min.js"></script>
		<script src="assets/js/util.js"></script>
		<!--[if lte IE 8]><script src="assets/js/ie/respond.min.js"></script><![endif]-->
		<script src="assets/js/main.js"></script>

	</body>
</html>